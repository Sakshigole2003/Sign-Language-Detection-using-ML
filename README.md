Sign language serves as a crucial means of communication for the deaf and hard of hearing community.
However, the interpretation of sign language gestures by individuals who do not understand the language can be challenging. 
This paper presents a comprehensive overview of utilizing machine learning (ML) techniques for sign language detection, aiming to bridge communication gaps between sign language users and non-users. 
Sign language serves as a primary mode of communication for the deaf and hard of hearing community. 
Recent advancements in machine learning (ML) have sparked interest in developing automated systems to interpret sign language gestures, enabling smoother communication between individuals who use sign language and those who do not.
This paper presents a comprehensive review of the state-of-the-art techniques in sign language detection using ML.
![image](https://github.com/user-attachments/assets/5615b125-bf96-448d-8893-20d1e33e8d8c)
DEMO OUTPUT:
![image](https://github.com/user-attachments/assets/bd2630fd-5923-4f21-8f6d-a06727c76999)

INSTRUCTION :
1. Run datacollection.py file and capture all the images u want within the proper dataset.
2. after that use https://teachablemachine.withgoogle.com/train/image to train the ML model
3. after that download the keras file and navigate it to the test.py file  
